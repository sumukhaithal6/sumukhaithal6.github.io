---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
urlcolor: blue
---
<style type="text/css">
    a {text-decoration:none;}
</style>
<br/>

[**S<sup>3</sup>VAADA: Submodular Subset Selection for Virtual Adversarial Active Domain Adaptation**]((/publications/s3_vaada.md))<br/>
Accepted at ICCV 2021! (More details coming Soon)<br/>
<br/>
<br/>

[**Robustness to Augmentations as a Generalization Metric**]((/publications/robustness_to_augmentations_as_a_generalization_metric.md))<br/>
**Sumukh Aithal K**\*, Dhruva Kashyap *, Natarajan Subramanyam <br/>
1st Runner Up in Predicting Generalization in Deep Learning, **NeurIPS 2020 Competition Track** 
\[[<span style="color:blue">Paper</span>](https://arxiv.org/abs/2101.06459)\] \[[<span style="color:blue">Video</span>](https://slideslive.com/38942495/robustness-to-augmentations-as-a-generalization-metric)\] 
\[[<span style="color:blue">Code</span>](https://github.com/sumukhaithal6/pgdl)\]
<details>
  <summary>One Sentence Summary</summary>
  
  In this work, we developed a simple yet effective method to predict the generalization performance of a model by using the concept that models that are robust to augmentations are more generalizable than those which are not.

</details>
<!-- <br/> -->
<details>
  <summary>Abstract</summary>

  Generalization is the ability of a model to predict on unseen domains and is a fundamental task in machine learning. Several generalization bounds, both theoretical and empirical have been proposed but they do not provide tight bounds. In this work, we propose a simple yet effective method to predict the generalization performance of a model by using the concept that models that are robust to augmentations are more generalizable than those which are not. We experiment with several augmentations and composition of augmentations to check the generalization capacity of a model. We also provide a detailed motivation behind the proposed method. The proposed generalization metric is calculated based on the change in the modelâ€™s output after augmenting the input. The proposed method was the first runner up solution for the competition "Predicting Generalization in Deep Learning".
</details>

<br/>
<br/>

**[Domain Shift in Capsule Networks](/publications/domain_shift_capsule_networks)**<br/>
Rajath S\*, **Sumukh Aithal K**\*, Natarajan Subramanyam <br/>
10th International Conference on Pattern Recognition Applications and Methods (**ICPRAM 2021**)
\[[<span style="color:blue">Paper</span>](https://www.scitepress.org/Papers/2021/102520/102520.pdf)\]

<details>

  <summary>One Sentence Summary</summary>

  In this paper, we analyze how well capsule networks adapt to new domains by experimenting with multiple routing algorithms and comparing it with CNNs.

</details>
<!-- <br/> -->

<details>

  <summary>Abstract</summary>

 Capsule Networks are an exciting deep learning architecture which overcomes some of the shortcomings of Convolutional Neural Networks (CNNs). Capsule networks aim to capture spatial relationships between parts of an object and exhibits viewpoint invariance. In practical computer vision, the training data distribution is different from the test distribution and the covariate shift affects the performance of the model. This problem is called Domain Shift. In this paper, we analyze how well capsule networks adapt to new domains by experimenting with multiple routing algorithms and comparing it with CNNs.

</details>

